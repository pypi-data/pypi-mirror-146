# generated by datamodel-codegen:
#   filename:  schema/entity/services/connections/database/databricksConnection.json
#   timestamp: 2022-04-11T06:51:08+00:00

from __future__ import annotations

from enum import Enum
from typing import List, Optional

from pydantic import BaseModel, Extra, Field, SecretStr

from . import connectionBasicType


class SupportedPipelineType8(Enum):
    Metadata = 'Metadata'


class DatabricksType(Enum):
    Databricks = 'Databricks'


class DatabricksScheme(Enum):
    databricks_connector = 'databricks+connector'


class DatabricksConnection(BaseModel):
    class Config:
        extra = Extra.forbid

    type: Optional[DatabricksType] = Field(
        DatabricksType.Databricks, description='Service Type'
    )
    scheme: Optional[DatabricksScheme] = Field(
        DatabricksScheme.databricks_connector,
        description='SQLAlchemy driver scheme options.',
    )
    username: Optional[str] = Field(
        None,
        description='username to connect  to the Databricks. This user should have privileges to read all the metadata in Databricks.',
    )
    password: Optional[SecretStr] = Field(
        None, description='password to connect to the Databricks.'
    )
    hostPort: Optional[str] = Field(None, description='Host and port of the Databricks')
    database: Optional[str] = Field(
        None,
        description='Database of the data source. This is optional parameter, if you would like to restrict the metadata reading to a single database. When left blank , OpenMetadata Ingestion attempts to scan all the databases in Databricks.',
    )
    token: Optional[str] = Field(None, description='')
    connectionOptions: Optional[connectionBasicType.ConnectionOptions] = None
    connectionArguments: Optional[connectionBasicType.ConnectionArguments] = None
    supportedPipelineTypes: Optional[List[SupportedPipelineType8]] = Field(
        ['Metadata'], description='Supported Metadata Extraction Pipelines.'
    )
