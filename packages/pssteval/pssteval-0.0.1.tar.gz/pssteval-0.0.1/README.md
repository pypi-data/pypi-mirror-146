# `pssteval`

This is a small set of tools for evaluation submissions for the 
(Post-Stroke Speech Transcription (PSST))[https://psst.study]] challenge.

## Installation
This package is installed via `pip`, like so:
```bash
pip install pssteval
```

## The Tools

Once installed, you will have three commands available for analysis of your work in the PSST challenge.

### ASR evaluation: `pssteval-asr`

Given file(s) containing your ASR generated transcripts, `pssteval-asr` computes phoneme 
the overall error rates for the file, and generates a detailed analysis of how the errors were computed.

The expected input file format is a tab-separated values (TSV) file with the required columns `utterance_id` and 
`asr_transcript`. As an example, here are the first five transcripts generated by the [baseline model](https://github.com/PSST-Challenge/psstbaseline):

```
utterance_id	asr_transcript
BU01a-BNT01-house	HH AW S
BU01a-BNT02-comb	K OW M
BU01a-BNT03-toothbrush	T UW TH B R AH SH
BU01a-BNT04-octopus	AA K T T T AH P UH S
BU01a-BNT05-bench	B EH N CH
```

If your transcripts are in `valid-asr.tsv`, you can get the ASR metrics by running:
```
pssteval-asr valid-asr.tsv --out-dir out/analysis 
```

This reports the PER and FER to the console, and the argument `--out-dir out/analysis` tells it to place the
detailed output (a `.json` file) in that directory.


### Correctness evaluation: `pssteval-correctness`

Similar to `pssteval-asr`, `pssteval-correctness` computes the binary classification metrics for your predictions. The 
input file is again a TSV, this time with the columns `utterance_id` and `prediction`. Here is what that would look like
for the baseline model:

```
utterance_id	prediction
BU01a-BNT01-house	True
BU01a-BNT02-comb	True
BU01a-BNT03-toothbrush	True
BU01a-BNT04-octopus	False
BU01a-BNT05-bench	True
```

To evaluate this file, if it were named `valid-correctness.tsv`, you would run:

```python
pssteval-correctness valid-correctness.tsv
```

This prints a confusion matrix as well as F1/precision/recall/accuracy metrics to the console. No analysis files are 
written.

### ASR Output Visualization: `pssteval-viewer`

With the analysis file generated by `pssteval-asr`, this tool gives you a chance to visually and aurally explore the 
output of the ASR. This tool is provided with limited support, but we hope you find it helpful, informative, and perhaps 
even fun!

Picking up where we left off with `pssteval-asr`, we generated an analysis file at
`out/analysis/details-asr-analysis.json`. Run `pssteval-viewer`, pointing to your analysis file(s): 

```python
pssteval-viewer out/analysis/details-asr-analysis.json
```

This starts a local web server at `http://localhost:8000`. If you navigate to this URL, you can explore your results in
an interactive way. Your transcripts with the highest FER appear first.

<img src="pssteval-viewer-list.png" style="max-width: 480px;">

If you click on an Utterance ID from the table, you can see a full trace of the feature distance 
computation. There's also an audio player, which uses [`psstdata`](https://github.com/PSST-Challenge/psstbaseline) to 
let you hear the utterance while you're looking at its trace. Also, hover over the feature names in a trace
to see the cost associated with it.

<img src="pssteval-viewer-detail.png" style="max-width: 480px;">


## Details about the error rates

### How Phoneme Error Rate (PER) is calculated

PER is calculated as `n_phoneme_errors / n_expected_phonemes`. To find `n_phoneme_errors`, we determine the smallest
count of insertions, deletions, and substitutions required to transform the 
"true" transcript to an ASR's predicted transcript.

### How PER and FER are calculated

In the tradition 
of Chomsky and Halle (1968), a phonological feature describes an articulatory quality of speech in quasi-binary terms. 
A value of [+] means a feature is present, [-] means it is absent. For example, a /g/ is [+voice], and /k/ is [-voice],
(and incidentally, [voice] is the only feature that distinguishes those two phonemes). A third value of [0] indicates that the 
feature is not relevant or necessary for the definition of that phoneme. For example, while [front], [back], [high], 
and [low] describe the various positions of the tongue in vowel articulation, these features aren't useful for describing
many consontants, such as /b/.

The FER is computed using the same Levenshtein distance algorithm as PER, except where our PER uses a cost of 1 for each 
insertion/deletion/substitution, FER's cost function considers "phonological distance" to compute this cost.   
[`phonologic`](https://github.com/rcgale/phonologic) to compute this metric. The core logic behind this computation is
very similar to [`panphon`'s](https://github.com/dmort27/panphon) `feature_edit_distance`. The FER is computed as 
`n_feature_errors / n_expected_features`, where `n_expected_features` is the number of phonemes in the "true" transcript
times the number of features in our feature system (24), and `n_feature_errors` is a total of a per-feature comparison, 
costing a point for mismatches involving both [+] and [-], and half a point for [0] to either [+] or [-].

Unlike `panphon`, however, we include special rules for the case of diphthongs (vowels where articulation starts out 
like one phoneme and moves toward another). For the purposes of PSST, there are five dipthongs: /a͡ɪ/, /a͡ʊ/, /e͡ɪ/, /o͡ʊ/, 
and /ɔ͡ɪ/.
In English, these phonemes emphasize the first vowel, and although articulation moves toward the the second vowel, it 
usually won't quite arrive there (Ladefoged and Johnson, 2015, pp97-99.) As such, we define a diphthongs feature set as
that of its first vowel, but for the features which differ in the second vowel, we use two new symbols: [+-] for 
features moving from present to absent, and [-+] for those moving from absent to present. For the cost function, [+-] is considered "mostly present", and [-+] as "mostly
absent," with half the costs associated with their fully present/absent counterparts. So our complete definition of 
feature costs is shown here:

| Cost | Feature Changes                                                                                                                                                                                                                         |
|------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1    | <div style="text-align: center">[-feature]&nbsp;↔&nbsp;[+feature]</div>                                                                                                                                                                 |
| 0.75 | <div style="text-align: center">[-feature]&nbsp;↔&nbsp;[+-feature]<br/>[-+feature]&nbsp;↔&nbsp;[+feature]</div>                                                                                                                         |
| 0.5  | [-feature]&nbsp;↔&nbsp;[0feature] <br /> <div style="text-align: center">[-+feature]&nbsp;↔&nbsp;[+-feature] <br /> [0feature]&nbsp;↔&nbsp;[+feature] </div>                                                                            |
| 0.25 | <div style="text-align: center">[-feature]&nbsp;↔&nbsp;[-+feature]<br /> [-+feature]&nbsp;↔&nbsp;[0feature] <br /> [0feature]&nbsp;↔&nbsp;[+-feature]  <br/> [+-feature]&nbsp;↔&nbsp;[+feature]</div>                                   |
| 0    | <div style="text-align: center"> [-feature]&nbsp;=&nbsp;[-feature] <br/> [-+feature]&nbsp;=&nbsp;[-+feature]<br/>[0feature]&nbsp;=&nbsp;[0feature]<br/>[+-feature]&nbsp;=&nbsp;[+-feature]<br/>[+feature]&nbsp;=&nbsp;[+feature] </div> |

### A little more on diphthongs
The vowels and features affected by the diphthong rules are shown in the table below. Note: /a͡ɪ/ and /a͡ʊ/ move from
[0tense] to [-tense], but were left as [0].

| ARPAbet | IPA  | Starting vowel | Example Word | Special diphthong features         |
|---------|------|----------------|--------------|------------------------------------|
| AY      | /a͡ɪ/ | /a/            | "buy"          | [-+high, +-low, -+front]           |
| AW      | /a͡ʊ/ | /a/            | "bough"        | [-+high, +-low, -+back, -+round]   |
| EY      | /e͡ɪ/ | /e/            | "bay"          | [-+high, +-tense]                  |
| OW      | /o͡ʊ/ | /o/            | "beau"         | [-+high, +-tense]                  |
| OY      | /ɔ͡ɪ/ | /ɔ/            | "boy"          | [-+high, -+front, +-back, +-round] |

Why go to this trouble? Without special treatment of diphthongs, we'd treat each part of the diphthong separately, so 
/e͡ɪ/ becomes /e/ and /ɪ/. This creates a major problem for 
vowel comparisons: any comparison between a monophthong and diphthong (and vice versa) will always be at least a full 
phoneme apart. For example, consider the distance from /kɔl/ "call" to /ko͡ʊl/ "coal". These two words are a minimal pair 
distinguished only by their vowels: /ɔ/ versus /o͡ʊ/. If we treat /o͡ʊ/ as two phonemes during distance calculation, 
we can go from /ɔ/ to /o/ with only [+tense], but then we must suffer the cost of a full /ʊ/ insertion. The way we
handle diphthongs eliminates this diphthong penalty, and is better aligned with the intuition
that resulted in ARPAbet using a single token for both monophthongs and diphthongs.s

